* Peer review and citations are the currency of research. If we can establish a channel for peer review and citation of code for toolkits, contribution may follow naturally. Any channel should be low-cost to implement, low-cost to execute, and employ a medium that is natural to the subject matter.
    * For example, a "Computational Letters" appendix in JEDC (or related) with IPython or IJulia notebooks.

        * low-cost implementation: add 1-2 pages to end of issue: title, two-line abstract, and link to a notebook "code vignette" (a la JSS)
        * low-cost execution: establish simple code comment and testing conventions (docstrings, simple unit tests) to lower review costs
        * establish permanent place to host e-publications [github, internet archive, arxiv.org]
        * establish simple formatting conventions
        * Thus peer review and citations happen in familiar way -- essentially "hacking"/piggy-backing on the traditional publication model.

    * Simpler approach: establish permanent place to host code online, and get top journals to agree that hosting here will fulfill their code-posting requirements. Thus models which use toolkit inherit a lot of pre-done work as far as commenting, testing, documenting, formatting.
